{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5085b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dask\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e489802",
   "metadata": {},
   "source": [
    "Weekly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae2314f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "## Fine tuning hyperparameters for the Random forest model\n",
    "\n",
    "# use the path\n",
    "path = r'C:/Users/endou012/emile/fileweek'                    \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3,4],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\n",
    "\n",
    "Best_grid=[]\n",
    "\n",
    "\n",
    "for i in range(63):\n",
    "    file=pd.read_csv(all_files[i],index_col='date')\n",
    "    file_x1=file[file.columns[1:]]\n",
    "    file_x=StandardScaler().fit_transform(file_x1)\n",
    "    file_y=file[file.columns[0]]\n",
    "    grid_search.fit(file_x, file_y)\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    Best_grid.append(best_grid) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d23a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Forest on entire data set and select the 30 most important features.\n",
    "\n",
    "Df_1=[]\n",
    "\n",
    "for i in range(63):\n",
    "    file=pd.read_csv(all_files[i],index_col='date')\n",
    "    file_x1=file[file.columns[1:]]\n",
    "    file_x=StandardScaler().fit_transform(file_x1)\n",
    "    file_y=file[file.columns[0]]\n",
    "    features=np.array(file_x1.columns)\n",
    "    rf = Best_grid[i]\n",
    "    rf.fit(file_x, file_y)\n",
    "    f_a = list(zip(features,rf.feature_importances_))\n",
    "    f_a.sort(key = lambda x : x[1])\n",
    "    A=[]\n",
    "    for j in range(56):\n",
    "        if f_a[0:56][j][1]>=0:\n",
    "              A.append(f_a[0:56][j][0])\n",
    "         \n",
    "       \n",
    "    file_xx=file_x1.drop(A,axis=1)\n",
    "    df=pd.concat([file_y,file_xx],axis=1)\n",
    "    df['first_lag_excess_return']=file_y.shift(periods=1)\n",
    "    df=df.fillna(0)\n",
    "    Df_1.append(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1504bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad45bdf",
   "metadata": {},
   "source": [
    "Monthly data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0deb8b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n",
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters tuning for Random Forest using GridSearchCV and fit the data\n",
    "\n",
    "# use the path\n",
    "path = r'C:/Users/endou012/emile/filemonth'                    \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3,4],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "\n",
    "\n",
    "Best_grid=[]\n",
    "\n",
    "\n",
    "for i in range(63):\n",
    "    file=pd.read_csv(all_files[i],index_col='date')\n",
    "    file_x1=file[file.columns[1:]]\n",
    "    file_x=StandardScaler().fit_transform(file_x1)\n",
    "    file_y=file[file.columns[0]]\n",
    "    grid_search.fit(file_x, file_y)\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    Best_grid.append(best_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fa2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Forest model on entire data sample and select the 30 most important features. We add the first lag target variable as predictor.\n",
    "\n",
    "Df_2=[]\n",
    "\n",
    "for i in range(63):\n",
    "    file=pd.read_csv(all_files[i],index_col='date')\n",
    "    file_x1=file[file.columns[1:]]\n",
    "    file_x=StandardScaler().fit_transform(file_x1)\n",
    "    file_y=file[file.columns[0]]\n",
    "    features=np.array(file_x1.columns)\n",
    "    rf = Best_grid[i]\n",
    "    rf.fit(file_x, file_y)\n",
    "    f_a = list(zip(features,rf.feature_importances_))\n",
    "    f_a.sort(key = lambda x : x[1])\n",
    "    A=[]\n",
    "    for j in range(56):\n",
    "        if f_a[0:56][j][1]>=0:\n",
    "              A.append(f_a[0:56][j][0])\n",
    "         \n",
    "       \n",
    "    file_xx=file_x1.drop(A,axis=1)\n",
    "    df=pd.concat([file_y,file_xx],axis=1)\n",
    "    df['first_lag_excess_return']=file_y.shift(periods=1)\n",
    "    df=df.fillna(0)\n",
    "    Df_2.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3a90e9",
   "metadata": {},
   "source": [
    "# Graphical representation of selected variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Df=[]\n",
    "\n",
    "for i in range(63):\n",
    "    file=pd.read_csv(all_files[i],index_col='date')\n",
    "    file_x1=file[file.columns[1:]]\n",
    "    file_x=StandardScaler().fit_transform(file_x1)\n",
    "    file_y=file[file.columns[0]]\n",
    "    features=np.array(file_x1.columns)\n",
    "    rf = Best_grid[i]\n",
    "    rf.fit(file_x, file_y)\n",
    "    f_a = list(zip(features,rf.feature_importances_))\n",
    "    f_a.sort(key = lambda x : x[1])\n",
    "       \n",
    "    Df.append(f_a[56:])\n",
    "    \n",
    "f_b=Df[62][0:15]\n",
    "f_b.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_b],[x[1] for x in f_b])\n",
    "    \n",
    "plt.savefig('imp_var62_1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76f0721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21656c43",
   "metadata": {},
   "source": [
    "Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a49b5730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly data\n",
    "Df_2[0].to_csv('C:/Users/endou012/emile/month/file_0.csv')\n",
    "Df_2[1].to_csv('C:/Users/endou012/emile/month/file_1.csv')\n",
    "Df_2[2].to_csv('C:/Users/endou012/emile/month/file_2.csv')\n",
    "Df_2[3].to_csv('C:/Users/endou012/emile/month/file_3.csv')\n",
    "Df_2[4].to_csv('C:/Users/endou012/emile/month/file_4.csv')    \n",
    "Df_2[5].to_csv('C:/Users/endou012/emile/month/file_5.csv')\n",
    "Df_2[6].to_csv('C:/Users/endou012/emile/month/file_6.csv')\n",
    "Df_2[7].to_csv('C:/Users/endou012/emile/month/file_7.csv')\n",
    "Df_2[8].to_csv('C:/Users/endou012/emile/month/file_8.csv') \n",
    "\n",
    "Df_2[9].to_csv('C:/Users/endou012/emile/month/file_9.csv')\n",
    "Df_2[10].to_csv('C:/Users/endou012/emile/month/file_10.csv')\n",
    "Df_2[11].to_csv('C:/Users/endou012/emile/month/file_11.csv')\n",
    "Df_2[12].to_csv('C:/Users/endou012/emile/month/file_12.csv')    \n",
    "Df_2[13].to_csv('C:/Users/endou012/emile/month/file_13.csv')\n",
    "Df_2[14].to_csv('C:/Users/endou012/emile/month/file_14.csv')\n",
    "Df_2[15].to_csv('C:/Users/endou012/emile/month/file_15.csv')\n",
    "Df_2[16].to_csv('C:/Users/endou012/emile/month/ile_16.csv')\n",
    "\n",
    "Df_2[17].to_csv('C:/Users/endou012/emile/month/ile_17.csv')\n",
    "Df_2[18].to_csv('C:/Users/endou012/emile/month/file_18.csv')\n",
    "Df_2[19].to_csv('C:/Users/endou012/emile/month/file_19.csv')\n",
    "Df_2[20].to_csv('C:/Users/endou012/emile/month/file_20.csv')    \n",
    "Df_2[21].to_csv('C:/Users/endou012/emile/month/file_21.csv')\n",
    "Df_2[22].to_csv('C:/Users/endou012/emile/month/file_22.csv')\n",
    "Df_2[23].to_csv('C:/Users/endou012/emile/month/file_23.csv')\n",
    "Df_2[24].to_csv('C:/Users/endou012/emile/month/file_24.csv') \n",
    "\n",
    "Df_2[25].to_csv('C:/Users/endou012/emile/month/file_25.csv')\n",
    "Df_2[26].to_csv('C:/Users/endou012/emile/month/file_26.csv')\n",
    "Df_2[27].to_csv('C:/Users/endou012/emile/month/file_27.csv')\n",
    "Df_2[28].to_csv('C:/Users/endou012/emile/month/file_28.csv')    \n",
    "Df_2[29].to_csv('C:/Users/endou012/emile/month/file_29.csv')\n",
    "Df_2[30].to_csv('C:/Users/endou012/emile/month/file_30.csv')\n",
    "Df_2[31].to_csv('C:/Users/endou012/emile/month/file_31.csv')\n",
    "Df_2[32].to_csv('C:/Users/endou012/emile/month/file_32.csv') \n",
    "\n",
    "\n",
    "Df_2[33].to_csv('C:/Users/endou012/emile/month/file_33.csv')\n",
    "Df_2[34].to_csv('C:/Users/endou012/emile/month/file_34.csv')    \n",
    "Df_2[35].to_csv('C:/Users/endou012/emile/month/file_35.csv')\n",
    "Df_2[36].to_csv('C:/Users/endou012/emile/month/file_36.csv')\n",
    "Df_2[37].to_csv('C:/Users/endou012/emile/month/file_37.csv')\n",
    "Df_2[38].to_csv('C:/Users/endou012/emile/month/file_38.csv') \n",
    "\n",
    "Df_2[39].to_csv('C:/Users/endou012/emile/month/file_39.csv')\n",
    "Df_2[40].to_csv('C:/Users/endou012/emile/month/file_40.csv')\n",
    "Df_2[41].to_csv('C:/Users/endou012/emile/month/file_41.csv')\n",
    "Df_2[42].to_csv('C:/Users/endou012/emile/month/file_42.csv')    \n",
    "Df_2[43].to_csv('C:/Users/endou012/emile/month/file_43.csv')\n",
    "Df_2[44].to_csv('C:/Users/endou012/emile/month/file_44.csv')\n",
    "Df_2[45].to_csv('C:/Users/endou012/emile/month/file_45.csv')\n",
    "Df_2[46].to_csv('C:/Users/endou012/emile/month/file_46.csv')\n",
    "\n",
    "Df_2[47].to_csv('C:/Users/endou012/emile/month/file_47.csv')\n",
    "Df_2[48].to_csv('C:/Users/endou012/emile/month/file_48.csv')\n",
    "Df_2[49].to_csv('C:/Users/endou012/emile/month/file_49.csv')\n",
    "Df_2[50].to_csv('C:/Users/endou012/emile/month/file_50.csv')    \n",
    "Df_2[51].to_csv('C:/Users/endou012/emile/month/file_51.csv')\n",
    "Df_2[52].to_csv('C:/Users/endou012/emile/month/file_52.csv')\n",
    "Df_2[53].to_csv('C:/Users/endou012/emile/month/file_53.csv')\n",
    "Df_2[54].to_csv('C:/Users/endou012/emile/month/file_54.csv') \n",
    "\n",
    "Df_2[55].to_csv('C:/Users/endou012/emile/month/file_55.csv')\n",
    "Df_2[56].to_csv('C:/Users/endou012/emile/month/file_56.csv')\n",
    "Df_2[57].to_csv('C:/Users/endou012/emile/month/file_57.csv')\n",
    "Df_2[58].to_csv('C:/Users/endou012/emile/month/file_58.csv')    \n",
    "Df_2[59].to_csv('C:/Users/endou012/emile/month/file_59.csv')\n",
    "Df_2[60].to_csv('C:/Users/endou012/emile/month/file_60.csv')\n",
    "Df_2[61].to_csv('C:/Users/endou012/emile/month/file_61.csv')\n",
    "Df_2[62].to_csv('C:/Users/endou012/emile/month/file_62.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edc51953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly data\n",
    "\n",
    "Df_1[0].to_csv('C:/Users/endou012/emile/week/file_0.csv')\n",
    "Df_1[1].to_csv('C:/Users/endou012/emile/week/file_1.csv')\n",
    "Df_1[2].to_csv('C:/Users/endou012/emile/week/file_2.csv')\n",
    "Df_1[3].to_csv('C:/Users/endou012/emile/week/file_3.csv')\n",
    "Df_1[4].to_csv('C:/Users/endou012/emile/week/file_4.csv')    \n",
    "Df_1[5].to_csv('C:/Users/endou012/emile/week/file_5.csv')\n",
    "Df_1[6].to_csv('C:/Users/endou012/emile/week/file_6.csv')\n",
    "Df_1[7].to_csv('C:/Users/endou012/emile/week/file_7.csv')\n",
    "Df_1[8].to_csv('C:/Users/endou012/emile/week/file_8.csv') \n",
    "\n",
    "Df_1[9].to_csv('C:/Users/endou012/emile/week/file_9.csv')\n",
    "Df_1[10].to_csv('C:/Users/endou012/emile/week/file_10.csv')\n",
    "Df_1[11].to_csv('C:/Users/endou012/emile/week/file_11.csv')\n",
    "Df_1[12].to_csv('C:/Users/endou012/emile/week/file_12.csv')    \n",
    "Df_1[13].to_csv('C:/Users/endou012/emile/week/file_13.csv')\n",
    "Df_1[14].to_csv('C:/Users/endou012/emile/week/file_14.csv')\n",
    "Df_1[15].to_csv('C:/Users/endou012/emile/week/file_15.csv')\n",
    "Df_1[16].to_csv('C:/Users/endou012/emile/week/file_16.csv')\n",
    "\n",
    "Df_1[17].to_csv('C:/Users/endou012/emile/week/file_17.csv')\n",
    "Df_1[18].to_csv('C:/Users/endou012/emile/week/file_18.csv')\n",
    "Df_1[19].to_csv('C:/Users/endou012/emile/week/file_19.csv')\n",
    "Df_1[20].to_csv('C:/Users/endou012/emile/week/file_20.csv')    \n",
    "Df_1[21].to_csv('C:/Users/endou012/emile/week/file_21.csv')\n",
    "Df_1[22].to_csv('C:/Users/endou012/emile/week/file_22.csv')\n",
    "Df_1[23].to_csv('C:/Users/endou012/emile/week/file_23.csv')\n",
    "Df_1[24].to_csv('C:/Users/endou012/emile/week/file_24.csv') \n",
    "\n",
    "Df_1[25].to_csv('C:/Users/endou012/emile/week/file_25.csv')\n",
    "Df_1[26].to_csv('C:/Users/endou012/emile/week/file_26.csv')\n",
    "Df_1[27].to_csv('C:/Users/endou012/emile/week/file_27.csv')\n",
    "Df_1[28].to_csv('C:/Users/endou012/emile/week/file_28.csv')    \n",
    "Df_1[29].to_csv('C:/Users/endou012/emile/week/file_29.csv')\n",
    "Df_1[30].to_csv('C:/Users/endou012/emile/week/file_30.csv')\n",
    "Df_1[31].to_csv('C:/Users/endou012/emile/week/file_31.csv')\n",
    "Df_1[32].to_csv('C:/Users/endou012/emile/week/file_32.csv') \n",
    "\n",
    "\n",
    "Df_1[33].to_csv('C:/Users/endou012/emile/week/file_33.csv')\n",
    "Df_1[34].to_csv('C:/Users/endou012/emile/week/file_34.csv')    \n",
    "Df_1[35].to_csv('C:/Users/endou012/emile/week/file_35.csv')\n",
    "Df_1[36].to_csv('C:/Users/endou012/emile/week/file_36.csv')\n",
    "Df_1[37].to_csv('C:/Users/endou012/emile/week/file_37.csv')\n",
    "Df_1[38].to_csv('C:/Users/endou012/emile/week/file_38.csv') \n",
    "\n",
    "Df_1[39].to_csv('C:/Users/endou012/emile/week/file_39.csv')\n",
    "Df_1[40].to_csv('C:/Users/endou012/emile/week/file_40.csv')\n",
    "Df_1[41].to_csv('C:/Users/endou012/emile/week/file_41.csv')\n",
    "Df_1[42].to_csv('C:/Users/endou012/emile/week/file_42.csv')    \n",
    "Df_1[43].to_csv('C:/Users/endou012/emile/week/file_43.csv')\n",
    "Df_1[44].to_csv('C:/Users/endou012/emile/week/file_44.csv')\n",
    "Df_1[45].to_csv('C:/Users/endou012/emile/week/file_45.csv')\n",
    "Df_1[46].to_csv('C:/Users/endou012/emile/week/file_46.csv')\n",
    "\n",
    "Df_1[47].to_csv('C:/Users/endou012/emile/week/file_47.csv')\n",
    "Df_1[48].to_csv('C:/Users/endou012/emile/week/file_48.csv')\n",
    "Df_1[49].to_csv('C:/Users/endou012/emile/week/file_49.csv')\n",
    "Df_1[50].to_csv('C:/Users/endou012/emile/week/file_50.csv')    \n",
    "Df_1[51].to_csv('C:/Users/endou012/emile/week/file_51.csv')\n",
    "Df_1[52].to_csv('C:/Users/endou012/emile/week/file_52.csv')\n",
    "Df_1[53].to_csv('C:/Users/endou012/emile/week/file_53.csv')\n",
    "Df_1[54].to_csv('C:/Users/endou012/emile/week/file_54.csv') \n",
    "Df_1[55].to_csv('C:/Users/endou012/emile/week/file_55.csv')\n",
    "Df_1[56].to_csv('C:/Users/endou012/emile/week/file_56.csv')\n",
    "Df_1[57].to_csv('C:/Users/endou012/emile/week/file_57.csv')\n",
    "Df_1[58].to_csv('C:/Users/endou012/emile/week/file_58.csv')    \n",
    "Df_1[59].to_csv('C:/Users/endou012/emile/week/file_59.csv')\n",
    "Df_1[60].to_csv('C:/Users/endou012/emile/week/file_60.csv')\n",
    "Df_1[61].to_csv('C:/Users/endou012/emile/week/file_61.csv')\n",
    "Df_1[62].to_csv('C:/Users/endou012/emile/week/file_62.csv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033aa88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
